{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d5e039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2211 files belonging to 2 classes.\n",
      "Using 1769 files for training.\n",
      "Found 2211 files belonging to 2 classes.\n",
      "Using 442 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Nov 22 17:09:50 2022\n",
    "\n",
    "@author: SNUAI\n",
    "\"\"\"\n",
    "\n",
    "# !pip install -q git+https://github.com/tensorflow/docs\n",
    "# import tensorflow_docs as tfdocs\n",
    "# import tensorflow_docs.modeling\n",
    "# import tensorflow_docs.plots\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D,MaxPooling2D\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "plt.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "path = './total_data'\n",
    "img_height =128\n",
    "img_width =128 \n",
    "batch_size = 32\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    color_mode = 'grayscale',\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "valid_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "  path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  color_mode = 'grayscale',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "def regularized_padded_conv(*args, **kwargs):\n",
    "    return tf.keras.layers.Conv2D(*args, **kwargs, padding='same', kernel_regularizer=_regularizer,\n",
    "                                  kernel_initializer='he_normal', use_bias=False)\n",
    "    \n",
    "def regularized_padded_conv3(*args, **kwargs):\n",
    "    return tf.keras.layers.Conv2D(*args, **kwargs, kernel_size=3, kernel_regularizer=_regularizer,\n",
    "                                  padding='same', kernel_initializer='he_normal')\n",
    "    \n",
    "def bn_relu(x):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    return tf.keras.layers.ReLU()(x)\n",
    "\n",
    "## Shortcut = skip connection\n",
    "\n",
    "def shortcut(x, filters, stride):\n",
    "    if x.shape[-1] == filters:\n",
    "        return x\n",
    "    else:\n",
    "        x = regularized_padded_conv(filters, 1, strides=stride)(x)\n",
    "        return x\n",
    "\n",
    "def original_block(x, filters, stride=1, **kwargs):\n",
    "    c1 = regularized_padded_conv(filters, 3, strides=stride)(x)\n",
    "    c2 = regularized_padded_conv(filters, 3)(bn_relu(c1))\n",
    "    c2 = tf.keras.layers.BatchNormalization()(c2)\n",
    "    \n",
    "    x = shortcut(x, filters, stride)\n",
    "    return tf.keras.layers.ReLU()(x + c2)\n",
    "    \n",
    "def group_of_blocks(x,  num_blocks, filters, stride):\n",
    "    x = original_block(x, filters, stride)\n",
    "    for i in range(num_blocks-1):\n",
    "        x = original_block(x, filters)\n",
    "    return x\n",
    "\n",
    "## Resnet\n",
    "def Resnet(input_shape, \n",
    "           n_classes, \n",
    "           l2_reg=1e-4, \n",
    "           group_sizes=(64,128,256,512), \n",
    "           features=(1, 2, 2, 2), \n",
    "           strides=(1, 2, 2, 2),\n",
    "            first_conv={\"filters\": 64, \"kernel_size\": 3, \"strides\": 1}):\n",
    "    global _regularizer\n",
    "    _regularizer = tf.keras.regularizers.l2(l2_reg)\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    flow = regularized_padded_conv(**first_conv)(inputs)\n",
    "    \n",
    "    flow = bn_relu(flow)\n",
    "    \n",
    "    for block_idx, (group_size, feature, stride) in enumerate(zip(group_sizes, features, strides)):\n",
    "        flow = group_of_blocks(flow,\n",
    "                               num_blocks=group_size,\n",
    "                               filters=feature,\n",
    "                               stride=stride)\n",
    "    \n",
    "    flow = bn_relu(flow)\n",
    "    \n",
    "    flow = tf.keras.layers.GlobalAveragePooling2D()(flow)\n",
    "    outputs = tf.keras.layers.Dense(n_classes, kernel_regularizer=_regularizer)(flow)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# model 생성\n",
    "def resnet18(l2_reg=1e-4, load_weights=False):\n",
    "    model = Resnet(input_shape=(128, 128, 1), n_classes=1, l2_reg=l2_reg, group_sizes=(2,2,2,2), features=(64,128,256,512),\n",
    "                   strides=(1, 2, 2, 2), first_conv={\"filters\": 64, \"kernel_size\": 3, \"strides\": 1})\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a5f36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "56/56 [==============================] - 25s 330ms/step - loss: 1.2271 - accuracy: 0.8615 - val_loss: 41.2488 - val_accuracy: 0.3507\n",
      "Epoch 2/20\n",
      "56/56 [==============================] - 16s 284ms/step - loss: 1.0217 - accuracy: 0.9633 - val_loss: 4.9512 - val_accuracy: 0.3507\n",
      "Epoch 3/20\n",
      "56/56 [==============================] - 16s 285ms/step - loss: 0.9637 - accuracy: 0.9853 - val_loss: 3.5860 - val_accuracy: 0.4434\n",
      "Epoch 4/20\n",
      "56/56 [==============================] - 16s 286ms/step - loss: 0.9300 - accuracy: 0.9938 - val_loss: 1.7231 - val_accuracy: 0.8167\n",
      "Epoch 5/20\n",
      "56/56 [==============================] - 16s 291ms/step - loss: 0.8981 - accuracy: 0.9977 - val_loss: 1.0531 - val_accuracy: 0.9434\n",
      "Epoch 6/20\n",
      "56/56 [==============================] - 17s 297ms/step - loss: 0.8657 - accuracy: 1.0000 - val_loss: 0.9379 - val_accuracy: 0.9661\n",
      "Epoch 7/20\n",
      "56/56 [==============================] - 16s 294ms/step - loss: 0.8472 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.9615\n",
      "Epoch 8/20\n",
      "56/56 [==============================] - 16s 292ms/step - loss: 0.8274 - accuracy: 1.0000 - val_loss: 0.8926 - val_accuracy: 0.9729\n",
      "Epoch 9/20\n",
      "56/56 [==============================] - 16s 289ms/step - loss: 0.8079 - accuracy: 1.0000 - val_loss: 0.9287 - val_accuracy: 0.9525\n",
      "Epoch 10/20\n",
      "56/56 [==============================] - 16s 293ms/step - loss: 0.7884 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.9593\n",
      "Epoch 11/20\n",
      "56/56 [==============================] - 16s 293ms/step - loss: 0.7693 - accuracy: 1.0000 - val_loss: 0.8343 - val_accuracy: 0.9729\n",
      "Epoch 12/20\n",
      "56/56 [==============================] - 17s 295ms/step - loss: 0.7509 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.9480\n",
      "Epoch 13/20\n",
      "56/56 [==============================] - 16s 291ms/step - loss: 0.7316 - accuracy: 1.0000 - val_loss: 0.8047 - val_accuracy: 0.9729\n",
      "Epoch 14/20\n",
      "56/56 [==============================] - 17s 295ms/step - loss: 0.7131 - accuracy: 1.0000 - val_loss: 0.7795 - val_accuracy: 0.9683\n",
      "Epoch 15/20\n",
      "56/56 [==============================] - 16s 294ms/step - loss: 0.6950 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.9729\n",
      "Epoch 16/20\n",
      "56/56 [==============================] - 17s 295ms/step - loss: 0.6773 - accuracy: 1.0000 - val_loss: 0.7450 - val_accuracy: 0.9706\n",
      "Epoch 17/20\n",
      "56/56 [==============================] - 16s 293ms/step - loss: 0.6597 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.9661\n",
      "Epoch 18/20\n",
      "56/56 [==============================] - 17s 295ms/step - loss: 0.6428 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.9683\n",
      "Epoch 19/20\n",
      "56/56 [==============================] - 17s 296ms/step - loss: 0.6258 - accuracy: 1.0000 - val_loss: 0.7519 - val_accuracy: 0.9502\n",
      "Epoch 20/20\n",
      "56/56 [==============================] - 16s 293ms/step - loss: 0.6095 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.9774\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6853 - accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6853058338165283, 0.9773755669593811]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## 모델학습\n",
    "tf.keras.backend.clear_session()\n",
    "RESNET = resnet18()\n",
    "\n",
    "RESNET.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "RESNET.fit(train_dataset, validation_data=valid_dataset, epochs=20)\n",
    "RESNET.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce11aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
